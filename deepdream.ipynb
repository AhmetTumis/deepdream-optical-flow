{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initilize basic setup\n",
    "\n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "import scipy.ndimage as nd\n",
    "import PIL.Image\n",
    "from PIL import Image\n",
    "from IPython.display import clear_output, Image, display\n",
    "from google.protobuf import text_format\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "import glob\n",
    "%matplotlib inline\n",
    "import caffe\n",
    "\n",
    "# comment out below for cpu computing\n",
    "caffe.set_mode_gpu()\n",
    "caffe.set_device(0)\n",
    "\n",
    "import cv2\n",
    "\n",
    "def showarray(a, fmt='jpeg'):\n",
    "    a = np.uint8(a)\n",
    "    f = StringIO()\n",
    "    PIL.Image.fromarray(a)\n",
    "    display(PIL.Image.fromarray(a))\n",
    "        \n",
    "model_path = 'models/bvlc_googlenet/'\n",
    "net_fn   = model_path + 'deploy.prototxt'\n",
    "param_fn = model_path + 'bvlc_googlenet.caffemodel'\n",
    "\n",
    "model = caffe.io.caffe_pb2.NetParameter()\n",
    "text_format.Merge(open(net_fn).read(), model)\n",
    "model.force_backward = True\n",
    "open('tmp.prototxt', 'w').write(str(model))\n",
    "\n",
    "net = caffe.Classifier('tmp.prototxt', param_fn,\n",
    "                       mean = np.float32([104.0, 116.0, 122.0]),\n",
    "                       channel_swap = (2,1,0))\n",
    "\n",
    "\n",
    "def preprocess(net, img):\n",
    "    return np.float32(np.rollaxis(img, 2)[::-1]) - net.transformer.mean['data']\n",
    "\n",
    "def deprocess(net, img):\n",
    "    return np.dstack((img + net.transformer.mean['data'])[::-1])\n",
    "\n",
    "def make_step(net, step_size=1.5, end='inception_4c/output', jitter=32, clip=True):\n",
    "    '''Basic gradient ascent step.'''\n",
    "\n",
    "    src = net.blobs['data']\n",
    "    dst = net.blobs[end]\n",
    "\n",
    "    ox, oy = np.random.randint(-jitter, jitter+1, 2)\n",
    "    src.data[0] = np.roll(np.roll(src.data[0], ox, -1), oy, -2)\n",
    "            \n",
    "    net.forward(end=end)\n",
    "    dst.diff[:] = dst.data\n",
    "    net.backward(start=end)\n",
    "    g = src.diff[0]\n",
    "    src.data[:] += step_size/np.abs(g).mean() * g\n",
    "\n",
    "    src.data[0] = np.roll(np.roll(src.data[0], -ox, -1), -oy, -2)            \n",
    "    if clip:\n",
    "        bias = net.transformer.mean['data']\n",
    "        src.data[:] = np.clip(src.data, -bias, 255-bias)\n",
    "        \n",
    "def morphPicture(filename1, filename2, blend, width):\n",
    "    img1 = PIL.Image.open(filename1)\n",
    "    img2 = PIL.Image.open(filename2)\n",
    "    if width is not 0:\n",
    "        img2 = resizePicture(filename2, width)\n",
    "    return PIL.Image.blend(img1, img2, blend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initilize deepdream\n",
    "\n",
    "def deepdream(net, base_img, iter_n=15, octave_n=5, octave_scale=1.4, end='inception_4c/output', clip=True, show_img=False, **step_params):\n",
    "    octaves = [preprocess(net, base_img)]\n",
    "    for i in range(octave_n-1):\n",
    "        octaves.append(nd.zoom(octaves[-1], (1, 1.0/octave_scale,1.0/octave_scale), order=1))\n",
    "    \n",
    "    src = net.blobs['data']\n",
    "    detail = np.zeros_like(octaves[-1])\n",
    "    for octave, octave_base in enumerate(octaves[::-1]):\n",
    "        h, w = octave_base.shape[-2:]\n",
    "        if octave > 0:\n",
    "            h1, w1 = detail.shape[-2:]\n",
    "            detail = nd.zoom(detail, (1, 1.0*h/h1,1.0*w/w1), order=1)\n",
    "\n",
    "        src.reshape(1,3,h,w)\n",
    "        src.data[0] = octave_base+detail\n",
    "        for i in range(iter_n):\n",
    "            make_step(net, end=end, clip=clip, **step_params)\n",
    "            \n",
    "            vis = deprocess(net, src.data[0])\n",
    "            if not clip:\n",
    "                vis = vis*(255.0/np.percentile(vis, 99.98))\n",
    "            if show_img:\n",
    "                showarray(vis)\n",
    "            print(octave, i, end, vis.shape)\n",
    "            clear_output(wait=True)       \n",
    "        detail = src.data[0]-octave_base\n",
    "        if not show_img:\n",
    "            showarray(vis)\n",
    "    return deprocess(net, src.data[0])\n",
    "\n",
    "def fast_deepdream(net, base_img, iter_n=5, octave_n=5, octave_scale=1.4, end='inception_4c/output', **step_params):\n",
    "    octaves = [preprocess(net, base_img)]\n",
    "    for i in range(octave_n-1):\n",
    "        octaves.append(nd.zoom(octaves[-1], (1, 1.0/octave_scale,1.0/octave_scale), order=1))\n",
    "    \n",
    "    src = net.blobs['data']\n",
    "    detail = np.zeros_like(octaves[-1])\n",
    "    for octave, octave_base in enumerate(octaves[::-1]):\n",
    "        h, w = octave_base.shape[-2:]\n",
    "        if octave > 0:\n",
    "            h1, w1 = detail.shape[-2:]\n",
    "            detail = nd.zoom(detail, (1, 1.0*h/h1,1.0*w/w1), order=1)\n",
    "\n",
    "        src.reshape(1,3,h,w)\n",
    "        src.data[0] = octave_base+detail\n",
    "        for i in range(iter_n):\n",
    "            make_step(net, end=end, clip=True, **step_params)\n",
    "            \n",
    "            vis = deprocess(net, src.data[0])\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "        detail = src.data[0]-octave_base\n",
    "    return deprocess(net, src.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video to frames\n",
    "vidcap = cv2.VideoCapture('25fpsyunus.mp4')\n",
    "success,image = vidcap.read()\n",
    "index = 1\n",
    "while success:\n",
    "    cv2.imwrite(\"./input/%04d.jpg\" % index, image)\n",
    "    success, image = vidcap.read()\n",
    "    index += 1\n",
    "    \n",
    "print('Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.float32(PIL.Image.open('input/0001.jpg'))\n",
    "showarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding out best settings for deepdream\n",
    "iter, octave = 4, 3\n",
    "\n",
    "_ = deepdream(net, img, iter_n=iter, octave_n=octave, clip=True, show_img=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deepdream frames\n",
    "blendstatic = 0.1\n",
    "\n",
    "img_arr = glob.glob('input/*.jpg')\n",
    "img_arr = sorted(img_arr)\n",
    "img_i = 1\n",
    "\n",
    "np_img = np.float32(PIL.Image.open(img_arr[0]))\n",
    "h, w, c = np_img.shape\n",
    "frame = fast_deepdream(net, np_img, iter_n=iter, octave_n=octave)\n",
    "np.clip(frame, 0, 255, out=frame)\n",
    "gray_img = cv2.cvtColor(np_img, cv2.COLOR_RGB2GRAY)\n",
    "PIL.Image.fromarray(np.uint8(frame)).save(\"output/%04d.jpg\"%img_i)\n",
    "\n",
    "for img in img_arr[1:]:\n",
    "    img_i += 1\n",
    "    np_prev_img = np_img\n",
    "    gray_prev_img = gray_img\n",
    "    \n",
    "    np_img = np.float32(PIL.Image.open(img))\n",
    "    gray_img = cv2.cvtColor(np_img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    flow = cv2.calcOpticalFlowFarneback(gray_prev_img, gray_img, None, pyr_scale=0.5, levels=3, winsize=15, iterations=3, poly_n=5, poly_sigma=1.2, flags=0)\n",
    "    inv_flow = flow\n",
    "    flow = -flow\n",
    "    flow[:, :, 0] += np.arange(w)\n",
    "    flow[:, :, 1] += np.arange(h)[:, np.newaxis]\n",
    "    \n",
    "    framediff = morphPicture(np_img, frame, 0.9, 0) - np_prev_img\n",
    "    framediff = cv2.remap(framediff, flow, None, cv2.INTER_LINEAR)\n",
    "    frame_flow = np_img + framediff\n",
    "    \n",
    "    magnitude, angle = cv2.cartToPolar(inv_flow[...,0], inv_flow[...,1])\n",
    "    norm_mag = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX);\n",
    "    ret, mask = cv2.threshold(norm_mag, 6, 255, cv2.THRESH_BINARY);\n",
    "    flow_mask = mask.astype(np.uint8).reshape((h, w, 1))\n",
    "    frame_flow_masked = cv2.bitwise_and(frame_flow, frame_flow, mask=flow_mask)\n",
    "    \n",
    "    background_blendimg = cv2.addWeighted(np_img, (1-blendstatic), frame, blendstatic, 0)\n",
    "    background_masked =  cv2.bitwise_and(background_blendimg, background_blendimg, mask=cv2.bitwise_not(flow_mask))\n",
    "    \n",
    "    frame = frame_flow_masked + background_masked\n",
    "    frame = fast_deepdream(net, frame, iter_n=iter, octave_n=octave)\n",
    "    np.clip(frame, 0, 255, out=frame)\n",
    "    PIL.Image.fromarray(np.uint8(frame)).save(\"output/%04d.jpg\"%img_i)\n",
    "    \n",
    "    print(\"output/%04d.jpg\"%img_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate deepdreamed video\n",
    "fps = 25\n",
    "frameSize = (640, 360)\n",
    "\n",
    "mp4_fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "avi_fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "\n",
    "out = cv2.VideoWriter('output_video.avi', avi_fourcc, fps, frameSize)\n",
    "for filename in sorted(glob.glob('output/*.jpg')):\n",
    "    img = cv2.imread(filename)\n",
    "    out.write(img)\n",
    "\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete everything in input and output file.\n",
    "import os\n",
    "\n",
    "def delete_all(pathtodelete):\n",
    "    files = glob.glob(pathtodelete + '/*')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "\n",
    "delete_all('input')\n",
    "delete_all('output')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}